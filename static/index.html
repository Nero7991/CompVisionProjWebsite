<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
    | ECE, Virginia Tech | Fall 2021: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
  <style>
    body {
      padding-top: 60px;
      /* 60px to make the container go all the way to the bottom of the topbar */
    }

    .vis {
      color: #3366CC;
    }

    .data {
      color: #FF9900;
    }
  </style>

  <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
  <link href="css/custom.css" rel="stylesheet">


  <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
  <div class="container">
    <div class="page-header">

      <!-- Title and Name -->
      <h1>Facial keypoint detection</h1>
      <span style="font-size: 20px; line-height: 1.5em;"><strong>Sindhu Chava, Oren Collaco</strong></span><br>
      <span style="font-size: 18px; line-height: 1.5em;">Fall 2021 ECE 4554/5554 Computer Vision: Course
        Project</span><br>
      <span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
      <hr>

      <!--Please see <a href="http://vision.cs.utexas.edu/projects/adapted_attributes/">this</a> for an example of how to lay out the various details of your project. You may need to provide more details than this, because you will not be submitting an associated paper to accompany the webpage. So the page should be self-contained.-->

      <!-- Goal -->
      <h3>Abstract</h3>

      Facial features vary greatly from one individual to another, and even for a single individual, there is a large
      amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. In this project,
      We trained a multilayer perceptron network using a unprocessed dataset and a augmented data set and used the
      trained model to predict facial key points in a test data set and compared the accuracy of the two trained models.
      Detecting key points on face images are building blocks of several applications:<br><br>
      1. Face filters, which overlay facial photographs with funny objects, have become commonplace like snapchat.<br>
      2. Analysing facial expressions play an important role in developing real-time applications for biometrics,
      detecting drowsiness and reading a person's emotions.<br>
      3. Unlocking mobile phones, determine age of the person<br>
      4. Detecting dysmorphic facial signs for medical diagnosis
      <br><br>
      <!-- figure -->
      <!-- Main Illustrative Figure -->
      <!-- A figure that conveys the main idea behind the project or the main application being addressed. -->

      <div style="text-align: center;">
        <img class="img1" alt="" src="cv-train.png">
      </div>
      <div style="text-align: center;">
        <img class="img2" alt="" src="cv-block.png">
      </div>
      <!-- Introduction -->
      <h3>Introduction</h3>
      One of the most distinguishing features of humans is their face. Through evolution, it has become the primary
      method of identifying other people and expressing feelings and emotions to others. Identifying and classifying
      faces thus is a crucial task in many computer vision applications. Basic identification of faces allows one to
      track the number of people in an image. Identifying key facial features can be potentially used to identify facial
      expressions, which can be further extrapolated to recognising emotions and identifying emotions of a person in an
      image opens a lot of doors to perform further processing such as in criminal situations where it is crucial to
      know what state of mind someone is in.
      <!-- <br>  Motivation behind the problem you are solving, what applications it has, any brief background on the particular domain you are working in (if not regular RBG photographs), etc. If you are using a new way to solve an existing problem, briefly mention and describe the existing approaches and tell us how your approach is new. -->

      <br><br>


      <!-- <h3>Problem statement</h3>
Facial Key points Detection is an important and challenging computer vision Kaggle competition problem, which involves detecting facial points like centers and corners of the eyes, eyebrows, nose and mouth, among other facial features. The problem is to predict the (x, y) real valued co-ordinates in the space of image pixels of the key points for a given face image.
<br><br> -->

      <!-- <h3>Basic Idea</h3> -->
      <br><br>

      <br><br>

      <!-- Approach -->
      <h3>Approach</h3>
      Dataset consists of both images and tabular data in the form of a .csv file, which contain facial key coordinates.
      Data preprocessing is required to remove redundancies and fill missing values. Since the dataset contains less
      volume of data, data augmentation would be a great help to increase the number of images. This data after the
      split into train and test can be passed to the model to get predictions. The success of the model can be measured
      by getting the least RMSE.<br><br>
      <ul>
        <li>Data preprocessing - To avoid mis-interpretation of the data, missing values, pixel strings need to be
          treated.</li>
        <div class="subpoints">
          1. Data imputation to replace NaN values<br>
          <div style="text-align: center;">
            <img class="img3" alt="" src="cv-missing.png">
          </div>

          <!-- 2. Remove space in pixel value strings<br> -->
          3. Visualisation to understand insights of the data<br>
          <div style="text-align: center;">
            <img class="img1" alt="" src="cv-hists.png">
          </div>
          <div style="text-align: center;">
            <img class="img2" alt="" src="cv-correlation.png">
          </div>
        </div>
        <li>Data Augmentation – After splitting the data into train and test, the train data considerably reduces.
          However, CNN requires more data to understand the complexity in the images. To solve this problem data needs
          to be augmented.</li>
        <div class="subpoints">
          <!-- 1. Linear Contrast and gaussian blurring <br> -->
          2. Scaling and rotating images <br>
          <div style="text-align: center;">
            <img class="img3" alt="" src="cv-rotate.png">
          </div>
        </div>
        3. Horizontal flip<br>
        <div style="text-align: center;">
          <img class="img3" alt="" src="cv-flip.png">
        </div>
    </div>
    <li>Split data into train and test data</li>
    <div class="subpoints">
      1. Split train data into train and validation sets<br>
    </div>
    <li>Modelling</li>
    <div class="subpoints">
      1. Multi-Layer Perceptron with a couple of hidden layers and one output layer<br>
      <!-- 2. Inception model<br> -->
    </div>
    <li>Predicting key points for test images<br></li>
    <li>To understand how well the model is performing metrics like RMSE(Root Mean Square Error) can be used to
      understand the extent of prediction of key points.</li>
    </ul>


    <br>
    <!-- Results -->
    <h3>Experiments</h3>
    <h5></h5>
    <h4>Datasets</h4>
    Data is taken from Facial Key points Detection kaggle challenge. The data mainly consists of face images and
    coordinates of tips of eyes, eyebrow, nose and mouth in a .csv file.<br>
    <h4>Experiments</h4>
    In this project, we would experiment with data preprocessing like handling missing NaN values, treating pixel
    strings and visualisation of data. For the data augmentation, we plan to explore Linear Contrast and gaussian
    blurring, Scaling and rotating images and horizontal flip of the images. As a part of modelling, to get the basic
    idea of perceptron, we intend to use Multi-Layer Perceptron with a couple of hidden layers and one output layer,
    also a CNN inception model. RMSE can be used as a metric to understand the prediction of key point coordinates on
    the images.
    <!--The standard deviation of the x, y co-ordinates produced by the two trained convolution neural network models against the co-ordinates we manually create. This will performed for a small set of images and the standard deviation for both the models will be presented.-->
    <!--Provide details about the experimental set up (number of images/videos, number of datasets you experimented with, train/test split if you used machine learning algorithms, etc.). Describe the evaluation metrics you used to evaluate how well your approach is working. Include clear figures and tables, as well as illustrative qualitative examples if appropriate. Be sure to include obvious baselines to see if your approach is doing better than a naive approach (e.g. for classification accuracy, how well would a classifier do that made random decisions?). Also discuss any parameters of your algorithms, and tell us how you set the values of those parameters. You can also show us how the performance varies as you change those parameter values. Be sure to discuss any trends you see in your results, and explain why these trends make sense. Are the results as expected? Why?-->

    <br><br>

    <!-- Main Results Figure -->
    <!--<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>
-->

    <!-- Results -->
    <h3>Qualitative results</h3>
    To understand how well the model is performing metrics like RMSE(Root Mean Square Error) can be used to understand
    the extent of prediction of key points.
    <br><br>
    <div style="text-align: center;">
      <img class="img2" alt="" src="cv-rmse.png">
    </div>

    <div style="text-align: center;">
      <img class="img2" alt="" src="cv-rmse2.png">
    </div>


    <h3>Conclusion</h3>
    This report has described a convolutional neural network approach to facial keypoints detection. Most of the
    features
    have around 40% of the values missing. Thus, missing values are imputed with a mean of the feature as each feature's
    data follows a nearly normal distribution. To understand the relationship between features, we have plotted the
    features. As we can observe from the correlation matrix, features are not correlated; therefore, we used all the
    features for training the model. We trained the model with provided data and observed similar training and test
    errors. To address this issue, we have done data augmentation like horizontal flip, rotation of image by 15 degrees
    clockwise and anti-clockwise and trained the model with this data along with original data. There was a reduction in
    training and validation errors, indicating that neural work learned the patterns better with more data.
    <br>This project has a potential for improvement in the areas of model selection, data augmentation, and
    experimenting
    with hyperparameters. This project can be further extended to analyzing facial expressions, detecting dysmorphic
    facial signs for medical diagnosis, unlocking mobile phones, and many others.
    <!-- <br>  Motivation behind the problem you are solving, what applications it has, any brief background on the particular domain you are working in (if not regular RBG photographs), etc. If you are using a new way to solve an existing problem, briefly mention and describe the existing approaches and tell us how your approach is new. -->

    <br><br>

    <!-- Main Results Figure 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br>
-->

    <!-- Conclusion -->
    <!--<h3>Conclusion</h3>
This report has described .... Briefly summarize what you have done. 
<br><br>-->

    <!-- References -->
    <h3>References</h3>
    <ul>
      <li>
        <div class="refs">Saptashwa Bhattacharyya. 2021.Facial Keypoints Detection: Image and Keypoints Augmentation.
          (May
          2001). Retrieved from
          https://towardsdatascience.com/facial-keypoints-detection-image-and-keypoints-augmentation-6c2ea824a59</div>
      </li>
      <li>
        <div class="refs">Nithiroj Tripatarasit. 2019.Facial Keypoints Detection with PyTorch. (May 2019). Retrieved
          from
          https://medium.com/diving-in-deep/facial-keypoints-detection-with-pytorch-86bac79141e4</div>
      </li>
      <li>
        <div class="refs">Naimish Agarwal, Artus Krohn-Grimberghe, Ranjana Vyas. 2017. Facial Key Points Detection using
          Deep Convolutional Neural Network. arXiv:1710.00977. Retrieved from https://arxiv.org/pdf/1710.00977.pdf</div>
      </li>
      <li>
        <div class="refs">Kaggle. 2020. Retrieved from
          https://www.kaggle.com/balraj98/data-augmentation-for-facial-keypoint-detection</div>
      </li>
    </ul>
    <br><br>


    <hr>
    <footer>
      <p>© 2021 Sindhu Chava, Oren Collaco</p>
    </footer>
  </div>
  </div>

  <br><br>

</body>

</html>